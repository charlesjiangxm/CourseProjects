{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(profile=\"full\") # or 'default'\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "import cupy as cp\n",
    "cp.cuda.Device(1).use()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True, linewidth=np.nan, precision=2, threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=256, bias=False)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=False)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "device = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n",
    "trainset = torchvision.datasets.MNIST('./data', train=True, transform=torchvision.transforms.ToTensor())\n",
    "testset = torchvision.datasets.MNIST('./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=6)\n",
    "        \n",
    "\n",
    "def vis_fc(act_list, layer_idx):\n",
    "    fc_act = act_list[layer_idx][0].data.cpu().numpy()\n",
    "    assert(len(fc_act)%20 == 0)\n",
    "    plt.imshow(fc_act.reshape(10,len(fc_act)//10), cmap='gray')\n",
    "    plt.suptitle('fc layer result, shape (1,500) ', fontsize=20)\n",
    "    plt.savefig(\"fc.png\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn.functional.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28*1, 256, bias=False)\n",
    "        self.fc2 = nn.Linear(256, 256, bias=False)\n",
    "        self.fc3 = nn.Linear(256, 10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(\"./model/mlp_model_1layer_256\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for MNIST dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (60000, 784) (60000,)\n",
      "test (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist_train_data = []\n",
    "mnist_train_label = []\n",
    "mnist_test_data = []\n",
    "mnist_test_label = []\n",
    "    \n",
    "for image, label in trainset:    \n",
    "    img = np.array(image.view(-1))\n",
    "    mnist_train_data.append(img)\n",
    "    mnist_train_label.append(label)\n",
    "    \n",
    "for image, label in testset:    \n",
    "    img = np.array(image.view(-1))\n",
    "    mnist_test_data.append(img)\n",
    "    mnist_test_label.append(label)\n",
    "    \n",
    "mnist_train_data = np.vstack(mnist_train_data)\n",
    "mnist_train_label = np.vstack(mnist_train_label).reshape(-1)\n",
    "mnist_test_data = np.vstack(mnist_test_data)\n",
    "mnist_test_label = np.vstack(mnist_test_label).reshape(-1)\n",
    "\n",
    "print(\"train\", mnist_train_data.shape, mnist_train_label.shape)\n",
    "print(\"test\", mnist_test_data.shape, mnist_test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1  2]\n",
      " [ 3  4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-2.41,  5.41]), array([[-0.91,  0.42],\n",
       "        [ 0.42,  0.91]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf = np.array([[-1,2],[3,4]])\n",
    "print(asdf)\n",
    "np.linalg.eigh(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf_inv = np.invert(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -3],\n",
       "       [-4, -5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdf_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-7.22,  2.22]), array([[ 0.48, -0.87],\n",
       "        [ 0.87,  0.48]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigh(asdf_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41,  0.  ],\n",
       "       [ 0.  ,  0.  ],\n",
       "       [ 1.41,  0.  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit_transform(asdf.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71,  0.71],\n",
       "       [ 0.71, -0.71]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.singular_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset after PCA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Testing Acceleration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 574 ms, total: 1min 6s\n",
      "Wall time: 8.56 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjiangan/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "%time logisticRegr.fit(mnist_train_data, mnist_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.2 ms, sys: 28.2 ms, total: 118 ms\n",
      "Wall time: 60.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time logisticRegr.score(mnist_test_data, mnist_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 84)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Scaler class object\n",
    "pca = PCA(n_components=0.9)\n",
    "# Perform PCA\n",
    "data_reduced = pca.fit_transform(mnist_test_data)\n",
    "print(data_reduced.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
